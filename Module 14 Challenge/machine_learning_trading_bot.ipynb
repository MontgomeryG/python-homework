{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Trading Bot\n",
    "\n",
    "In this Challenge, you’ll assume the role of a financial advisor at one of the top five financial advisory firms in the world. Your firm constantly competes with the other major firms to manage and automatically trade assets in a highly dynamic environment. In recent years, your firm has heavily profited by using computer algorithms that can buy and sell faster than human traders.\n",
    "\n",
    "The speed of these transactions gave your firm a competitive advantage early on. But, people still need to specifically program these systems, which limits their ability to adapt to new data. You’re thus planning to improve the existing algorithmic trading systems and maintain the firm’s competitive advantage in the market. To do so, you’ll enhance the existing trading signals with machine learning algorithms that can adapt to new data.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "Use the starter code file to complete the steps that the instructions outline. The steps for this Challenge are divided into the following sections:\n",
    "\n",
    "* Establish a Baseline Performance\n",
    "\n",
    "* Tune the Baseline Trading Algorithm\n",
    "\n",
    "* Evaluate a New Machine Learning Classifier\n",
    "\n",
    "* Create an Evaluation Report\n",
    "\n",
    "#### Establish a Baseline Performance\n",
    "\n",
    "In this section, you’ll run the provided starter code to establish a baseline performance for the trading algorithm. To do so, complete the following steps.\n",
    "\n",
    "Open the Jupyter notebook. Restart the kernel, run the provided cells that correspond with the first three steps, and then proceed to step four. \n",
    "\n",
    "1. Import the OHLCV dataset into a Pandas DataFrame.\n",
    "\n",
    "2. Generate trading signals using short- and long-window SMA values. \n",
    "\n",
    "3. Split the data into training and testing datasets.\n",
    "\n",
    "4. Use the `SVC` classifier model from SKLearn's support vector machine (SVM) learning method to fit the training data and make predictions based on the testing data. Review the predictions.\n",
    "\n",
    "5. Review the classification report associated with the `SVC` model predictions. \n",
    "\n",
    "6. Create a predictions DataFrame that contains columns for “Predicted” values, “Actual Returns”, and “Strategy Returns”.\n",
    "\n",
    "7. Create a cumulative return plot that shows the actual returns vs. the strategy returns. Save a PNG image of this plot. This will serve as a baseline against which to compare the effects of tuning the trading algorithm.\n",
    "\n",
    "8. Write your conclusions about the performance of the baseline trading algorithm in the `README.md` file that’s associated with your GitHub repository. Support your findings by using the PNG image that you saved in the previous step.\n",
    "\n",
    "#### Tune the Baseline Trading Algorithm\n",
    "\n",
    "In this section, you’ll tune, or adjust, the model’s input features to find the parameters that result in the best trading outcomes. (You’ll choose the best by comparing the cumulative products of the strategy returns.) To do so, complete the following steps:\n",
    "\n",
    "1. Tune the training algorithm by adjusting the size of the training dataset. To do so, slice your data into different periods. Rerun the notebook with the updated parameters, and record the results in your `README.md` file. Answer the following question: What impact resulted from increasing or decreasing the training window?\n",
    "\n",
    "> **Hint** To adjust the size of the training dataset, you can use a different `DateOffset` value&mdash;for example, six months. Be aware that changing the size of the training dataset also affects the size of the testing dataset.\n",
    "\n",
    "2. Tune the trading algorithm by adjusting the SMA input features. Adjust one or both of the windows for the algorithm. Rerun the notebook with the updated parameters, and record the results in your `README.md` file. Answer the following question: What impact resulted from increasing or decreasing either or both of the SMA windows?\n",
    "\n",
    "3. Choose the set of parameters that best improved the trading algorithm returns. Save a PNG image of the cumulative product of the actual returns vs. the strategy returns, and document your conclusion in your `README.md` file.\n",
    "\n",
    "#### Evaluate a New Machine Learning Classifier\n",
    "\n",
    "In this section, you’ll use the original parameters that the starter code provided. But, you’ll apply them to the performance of a second machine learning model. To do so, complete the following steps:\n",
    "\n",
    "1. Import a new classifier, such as `AdaBoost`, `DecisionTreeClassifier`, or `LogisticRegression`. (For the full list of classifiers, refer to the [Supervised learning page](https://scikit-learn.org/stable/supervised_learning.html) in the scikit-learn documentation.)\n",
    "\n",
    "2. Using the original training data as the baseline model, fit another model with the new classifier.\n",
    "\n",
    "3. Backtest the new model to evaluate its performance. Save a PNG image of the cumulative product of the actual returns vs. the strategy returns for this updated trading algorithm, and write your conclusions in your `README.md` file. Answer the following questions: Did this new model perform better or worse than the provided baseline model? Did this new model perform better or worse than your tuned trading algorithm?\n",
    "\n",
    "#### Create an Evaluation Report\n",
    "\n",
    "In the previous sections, you updated your `README.md` file with your conclusions. To accomplish this section, you need to add a summary evaluation report at the end of the `README.md` file. For this report, express your final conclusions and analysis. Support your findings by using the PNG images that you created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Establish a Baseline Performance\n",
    "\n",
    "In this section, you’ll run the provided starter code to establish a baseline performance for the trading algorithm. To do so, complete the following steps.\n",
    "\n",
    "Open the Jupyter notebook. Restart the kernel, run the provided cells that correspond with the first three steps, and then proceed to step four. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import the OHLCV dataset into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OHLCV dataset into a Pandas Dataframe\n",
    "ohlcv_df = pd.read_csv(\n",
    "    Path(\"./Resources/emerging_markets_ohlcv.csv\"), \n",
    "    index_col='date', \n",
    "    infer_datetime_format=True, \n",
    "    parse_dates=True\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "ohlcv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the date index and close columns\n",
    "signals_df = ohlcv_df.loc[:, [\"close\"]]\n",
    "\n",
    "# Use the pct_change function to generate returns from close prices\n",
    "signals_df[\"Actual Returns\"] = signals_df[\"close\"].pct_change()\n",
    "\n",
    "# Drop all NaN values from the DataFrame\n",
    "signals_df = signals_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate trading signals using short- and long-window SMA values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the short window and long window\n",
    "short_window = 4\n",
    "long_window = 100\n",
    "\n",
    "# Generate the fast and slow simple moving averages (4 and 100 days, respectively)\n",
    "signals_df['SMA_Fast'] = signals_df['close'].rolling(window=short_window).mean()\n",
    "signals_df['SMA_Slow'] = signals_df['close'].rolling(window=long_window).mean()\n",
    "\n",
    "signals_df = signals_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new Signal column\n",
    "signals_df['Signal'] = 0.0\n",
    "\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "signals_df.loc[(signals_df['Actual Returns'] >= 0), 'Signal'] = 1\n",
    "\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "signals_df.loc[(signals_df['Actual Returns'] < 0), 'Signal'] = -1\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df['Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the strategy returns and add them to the signals_df DataFrame\n",
    "signals_df['Strategy Returns'] = signals_df['Actual Returns'] * signals_df['Signal'].shift()\n",
    "\n",
    "signals_df.dropna(inplace=True)\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Strategy Returns to examine performance\n",
    "(1 + signals_df['Strategy Returns']).cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the data into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X\n",
    "X = signals_df[['SMA_Fast', 'SMA_Slow']].shift().dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = signals_df['Signal']\n",
    "\n",
    "# Review the value counts\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features DataFrames\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "display(X_test_scaled[:5])\n",
    "display(X_train_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the `SVC` classifier model from SKLearn's support vector machine (SVM) learning method to fit the training data and make predictions based on the testing data. Review the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC()\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "svm_training_signal = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "svm_training_signal[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Review the classification report associated with the `SVC` model predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_training_report_1 = classification_report(y_train, svm_training_signal)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_training_report_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict\n",
    "testing_signal_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "testing_signal_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "svm_testing_report_1 = classification_report(y_test, testing_signal_predictions)\n",
    "\n",
    "# Display the report\n",
    "print(svm_testing_report_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create a predictions DataFrame that contains columns for “Predicted” values, “Actual Returns”, and “Strategy Returns”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# # svm_pred_df = pd.DataFrame(svm_pred, columns=[\"Predicted\"])\n",
    "\n",
    "# # # Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = testing_signal_predictions\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df[\"Actual Returns\"]\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns']=(\n",
    "    predictions_df['Actual Returns'] * testing_signal_predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "# display(predictions_df.head())\n",
    "# display(predictions_df.tail())\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create a cumulative return plot that shows the actual returns vs. the strategy returns. Save a PNG image of this plot. This will serve as a baseline against which to compare the effects of tuning the trading algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tune the Baseline Trading Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you’ll tune, or adjust, the model’s input features to find the parameters that result in the best trading outcomes. You’ll choose the best by comparing the cumulative products of the strategy returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tune the training algorithm by adjusting the size of the training dataset. \n",
    "\n",
    "To do so, slice your data into different periods. Rerun the notebook with the updated parameters, and record the results in your `README.md` file. \n",
    "\n",
    "Answer the following question: What impact resulted from increasing or decreasing the training window?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a DateOffset of 3 months, let's try a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Change the training period to a year\n",
    "training_end = X.index.min() + DateOffset(months=12)\n",
    "\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Scale the features DataFrames\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC() \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    "# Use the testing data to make the model predictions\n",
    "svm_training_signal = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_training_report = classification_report(y_train, svm_training_signal)\n",
    "\n",
    "# Print the classification report\n",
    "print(f\"\"\"Train Classification Report:\n",
    "{svm_training_report}\"\"\")\n",
    "\n",
    "# Now predict\n",
    "testing_signal_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_test, testing_signal_predictions)\n",
    "\n",
    "# Display the report\n",
    "print(f\"\"\"___________________________________________________________________\n",
    "Test Classification Report:\n",
    "{testing_report}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origional model results\n",
    "print(svm_testing_report_1)\n",
    "print(svm_training_report_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy increased slightly, but our new model shows a value of 0 for precision for predicting -1.0; not good.\n",
    "Somehow by increasing our dateoffset from 3 to 12 months, our program can no longer predict when our signal is -1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# # svm_pred_df = pd.DataFrame(svm_pred, columns=[\"Predicted\"])\n",
    "\n",
    "# # # Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = testing_signal_predictions\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df[\"Actual Returns\"]\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns']=(\n",
    "    predictions_df['Actual Returns'] * testing_signal_predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "# display(predictions_df.head())\n",
    "# display(predictions_df.tail())\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 'months=6' to see if we get some precision back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Change the training period to a year\n",
    "training_end = X.index.min() + DateOffset(months=6)\n",
    "\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Scale the features DataFrames\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC() \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    "# Use the testing data to make the model predictions\n",
    "svm_training_signal = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_training_report = classification_report(y_train, svm_training_signal)\n",
    "\n",
    "# Print the classification report\n",
    "print(f\"\"\"Train Classification Report:\n",
    "{svm_training_report}\"\"\")\n",
    "\n",
    "# Now predict\n",
    "testing_signal_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_test, testing_signal_predictions)\n",
    "\n",
    "# Display the report\n",
    "print(f\"\"\"___________________________________________________________________\n",
    "Test Classification Report:\n",
    "{testing_report}\"\"\")\n",
    "\n",
    "# Origional model results\n",
    "print(f\"\"\"___________________________________________________________________\n",
    "Origional model results(train):\n",
    "{svm_training_report_1}\n",
    "_______________\n",
    "(test)\n",
    "{svm_testing_report_1}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, increasing the dateoffset to 6 months decreases our model's accuracy compared to the origional model using 3 months.\n",
    "Decreasing the dateoffset from 12 months to 6 months brings back some precision into our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# # svm_pred_df = pd.DataFrame(svm_pred, columns=[\"Predicted\"])\n",
    "\n",
    "# # # Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = testing_signal_predictions\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df[\"Actual Returns\"]\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns']=(\n",
    "    predictions_df['Actual Returns'] * testing_signal_predictions\n",
    ")\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "# display(predictions_df.head())\n",
    "# display(predictions_df.tail())\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot(title='DateOffset Changed to \\'months=6\\'')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems too good to be true... It would be interesting to test this on live data to see if the results hold true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Tune the trading algorithm by adjusting the SMA input features. \n",
    "\n",
    "Adjust one or both of the windows for the algorithm. Rerun the notebook with the updated parameters, and record the results in your `README.md` file. \n",
    "\n",
    "Answer the following question: What impact resulted from increasing or decreasing either or both of the SMA windows?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the short_window to 9 and the long_window to 50. The 9 and 50 period moving averages are emphasized in the day trading world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the date index and close columns\n",
    "signals_df = ohlcv_df.loc[:, [\"close\"]]\n",
    "# Use the pct_change function to generate returns from close prices\n",
    "signals_df[\"Actual Returns\"] = signals_df[\"close\"].pct_change()\n",
    "# Drop all NaN values from the DataFrame\n",
    "signals_df = signals_df.dropna()\n",
    "# Set the short window and long window\n",
    "short_window = 9\n",
    "long_window = 50\n",
    "# Generate the fast and slow simple moving averages (9 and 50 days, respectively)\n",
    "signals_df['SMA_Fast'] = signals_df['close'].rolling(window=short_window).mean()\n",
    "signals_df['SMA_Slow'] = signals_df['close'].rolling(window=long_window).mean()\n",
    "# Drop NaN\n",
    "signals_df = signals_df.dropna()\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new Signal column\n",
    "signals_df['Signal'] = 0.0\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "signals_df.loc[(signals_df['Actual Returns'] >= 0), 'Signal'] = 1\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "signals_df.loc[(signals_df['Actual Returns'] < 0), 'Signal'] = -1\n",
    "# Calculate the strategy returns and add them to the signals_df DataFrame\n",
    "signals_df['Strategy Returns'] = signals_df['Actual Returns'] * signals_df['Signal'].shift()\n",
    "signals_df.dropna(inplace=True)\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X\n",
    "X = signals_df[['SMA_Fast', 'SMA_Slow']].shift().dropna()\n",
    "# Review the DataFrame\n",
    "X.head()\n",
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = signals_df['Signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "# Change the training period to a year\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "# Scale the features DataFrames\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC() \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    "# Use the testing data to make the model predictions\n",
    "svm_training_signal = svm_model.predict(X_train_scaled)\n",
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_training_report = classification_report(y_train, svm_training_signal)\n",
    "# Print the classification report\n",
    "print(f\"\"\"Train Classification Report:\n",
    "{svm_training_report}\"\"\")\n",
    "# Now predict\n",
    "testing_signal_predictions = svm_model.predict(X_test_scaled)\n",
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_test, testing_signal_predictions)\n",
    "# Display the report\n",
    "print(f\"\"\"___________________________________________________________________\n",
    "Test Classification Report:\n",
    "{testing_report}\"\"\")\n",
    "\n",
    "# Origional model results\n",
    "print(f\"\"\"___________________________________________________________________\n",
    "Origional model results(train):\n",
    "{svm_training_report_1}\n",
    "_______________\n",
    "(test)\n",
    "{svm_testing_report_1}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = testing_signal_predictions\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df[\"Actual Returns\"]\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns']=(\n",
    "    predictions_df['Actual Returns'] * testing_signal_predictions\n",
    ")\n",
    "# Review the DataFrame\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. Very interesting that changing the long and short window to 9 and 50 does not work at all. Makes me wonder how the origional 4 and 100 short and long windows were choosen in the first place. Maybe, if we really wanted to see which combination of long/short windows works the best, we could iterate changing the two numbers and printing the classification reports to see which combination proves most useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose the set of parameters that best improved the trading algorithm returns. \n",
    "\n",
    "Save a PNG image of the cumulative product of the actual returns vs. the strategy returns, and document your conclusion in your `README.md` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluate a New Machine Learning Classifier\n",
    "\n",
    "In this section, you’ll use the original parameters that the starter code provided. But, you’ll apply them to the performance of a second machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  Import a new classifier, such as `AdaBoost`, `DecisionTreeClassifier`, or `LogisticRegression`. (For the full list of classifiers, refer to the [Supervised learning page](https://scikit-learn.org/stable/supervised_learning.html) in the scikit-learn documentation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, let's do some more analysis on our predictor variables so that we can choose which models are most likely to be the best ones to implement given the nature of our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's determing the correlation between our predictor variables.\n",
    "# We are using the scaled data as our predictor variables; the scaled data is derrived from the SMA fast and SMA slow.\n",
    "# We will use a correlation test on the SMA fast/slow instead of the scaled data\n",
    "display(X_test.head(3))\n",
    "display(X_test.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same on the scaled data to see if our above assumption is valid\n",
    "df_scaled = pd.DataFrame(X_train_scaled)#, #columns=column_names)\n",
    "\n",
    "display(df_scaled.head())\n",
    "\n",
    "df_scaled.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial anaysis that the correlation would be relatively the same between the raw and scaled data, was wrong.\n",
    "\n",
    "However, since we got a correlation of 0.947388 and -0.3857 between the raw and scaled variables, respectively, we will consider our predictor variables to exhbit multicollinearity. Therefore, we will seek to add new ML classifiers that do not require the assumption that a low level of multicolinearity exists in the dataset; classifiers such as logistic regression.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Using the original training data as the baseline model, fit another model with the new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a new classifier from SKLearn\n",
    "# We'll try decision trees first.\n",
    "from sklearn import tree\n",
    "# Initiate the model instance\n",
    "my_tree = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "# Change the training period to a year\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently we need not scaled the data before fitting the model.\n",
    "tree_model = my_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on train data\n",
    "tree_signal_pred = tree_model.predict(X_train)\n",
    "tree_signal_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "tree_training_report = classification_report(y_train, tree_signal_pred)\n",
    "# Print the classification report\n",
    "print(tree_training_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Backtest the new model to evaluate its performance. \n",
    "\n",
    "Save a PNG image of the cumulative product of the actual returns vs. the strategy returns for this updated trading algorithm, and write your conclusions in your `README.md` file. \n",
    "\n",
    "Answer the following questions: \n",
    "Did this new model perform better or worse than the provided baseline model? \n",
    "Did this new model perform better or worse than your tuned trading algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict unseen data\n",
    "tree_test_predictions = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_test, tree_test_predictions)\n",
    "# Display the report\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "# # svm_pred_df = pd.DataFrame(svm_pred, columns=[\"Predicted\"])\n",
    "# # # Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = tree_test_predictions\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df[\"Actual Returns\"]\n",
    "# Add the strategy returns to the DataFrame\n",
    "# predictions_df['Strategy Returns'] = signals_df[\"Strategy Returns\"]\n",
    "predictions_df['Strategy Returns']=(\n",
    "    predictions_df['Actual Returns'] * tree_test_predictions\n",
    ")\n",
    "# Review the DataFrame\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions: \n",
    "Did this new model perform better or worse than the provided baseline model? \n",
    "\n",
    "Did this new model perform better or worse than your tuned trading algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse and worse. \n",
    "\n",
    "I believe that the decision tree model overfitted the data, which is something that Sklearn's documentation hinted at; that a drawback of using decisions trees is their tendency to overfit the data. As we can see based on the above graph, in the beginning of the model's training/testing periods it outperforms the actual returns substantially. However, towards about the beginning of 2017 the strategy's returns begin to fall and never really recover. This decision tree model completely 'misses the point'.\n",
    "\n",
    "If we wanted to improve this tree model, we could start off by pruning the tree, a method used to reduce overfitting.\n",
    "\n",
    "Ultimately, we should also implement as many models as possible to determine which one seems best given this data set and our two highly-correlated variables. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
